{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pandas as pd\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "df = pd.read_csv('total.csv')\n",
    "\n",
    "df_sample = df.sample(frac=1)\n",
    "\n",
    "corpus_sample = df_sample['review'].tolist()\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(ngram_range=(1, 2), max_features= 1000)\n",
    "\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(corpus_sample)\n",
    "\n",
    "tfidf_matrix_sparse = csr_matrix(tfidf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = tfidf_vectorizer.get_feature_names_out()\n",
    "tfidf_df = pd.DataFrame.sparse.from_spmatrix(tfidf_matrix_sparse, columns=feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(212698, 12)\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            id  drugName  condition  \\\n",
      "0       163740      2156        193   \n",
      "1       206473      2067        173   \n",
      "2       159672       402        767   \n",
      "3        39293       827        789   \n",
      "4        97768       869         95   \n",
      "...        ...       ...        ...   \n",
      "212693  191035       593         20   \n",
      "212694  127085      2103        472   \n",
      "212695  187382      2429        646   \n",
      "212696   47128      3224        761   \n",
      "212697  215220      1961        163   \n",
      "\n",
      "                                                   review  rating        date  \\\n",
      "0       \"I've tried a few antidepressants over the yea...    10.0  2012-02-28   \n",
      "1       \"My son has Crohn's disease and has done very ...     8.0  2009-05-17   \n",
      "2                           \"Quick reduction of symptoms\"     9.0  2017-09-29   \n",
      "3       \"Contrave combines drugs that were used for al...     9.0  2017-03-05   \n",
      "4       \"I have been on this birth control for one cyc...     9.0  2015-10-22   \n",
      "...                                                   ...     ...         ...   \n",
      "212693  \"I wrote my first report in Mid-October of 201...    10.0  2015-05-31   \n",
      "212694  \"I was given this in IV before surgey. I immed...     1.0  2011-11-01   \n",
      "212695  \"Limited improvement after 4 months, developed...     2.0  2014-03-15   \n",
      "212696  \"I've been on thyroid medication 49 years, I s...    10.0  2015-09-19   \n",
      "212697  \"I've had chronic constipation all my adult li...     9.0  2014-12-13   \n",
      "\n",
      "        usefulCount  review_length  sentiment_score  Encoded_date  \\\n",
      "0                22            429          -0.4596          1465   \n",
      "1                17            258           0.0736           448   \n",
      "2                 3             29           0.0000          3505   \n",
      "3                35            752           0.4013          3297   \n",
      "4                 4            752           0.9559          2797   \n",
      "...             ...            ...              ...           ...   \n",
      "212693          125            689           0.9561          2653   \n",
      "212694           34            262          -0.4767          1346   \n",
      "212695           35             95          -0.7430          2211   \n",
      "212696           79            752           0.8084          2764   \n",
      "212697          116            332           0.6124          2484   \n",
      "\n",
      "        scaled_usefulCount  rating_scaled_usefulCount  \n",
      "0                 0.017041                   0.170411  \n",
      "1                 0.153153                   1.225225  \n",
      "2                 0.007353                   0.066176  \n",
      "3                 0.043970                   0.395729  \n",
      "4                 0.003208                   0.028869  \n",
      "...                    ...                        ...  \n",
      "212693            0.570776                   5.707763  \n",
      "212694            0.283333                   0.283333  \n",
      "212695            0.132576                   0.265152  \n",
      "212696            0.241590                   2.415902  \n",
      "212697            0.789116                   7.102041  \n",
      "\n",
      "[212698 rows x 12 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_df['sentiment_score'] = df['sentiment_score']\n",
    "tfidf_df['condition'] = df['condition']\n",
    "tfidf_df['rating'] = df['rating']\n",
    "tfidf_df['scaled_usefulCount'] = df['scaled_usefulCount']\n",
    "tfidf_df['rating_scaled_usefulCount'] = df['rating_scaled_usefulCount']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tfidf_df = pd.read_csv(\"tlfdf.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              10  100  10mg        11        12   14        15   16        18  \\\n",
      "0       0.000000  0.0   0.0  0.000000  0.000000  0.0  0.000000  0.0  0.000000   \n",
      "1       0.000000  0.0   0.0  0.139285  0.000000  0.0  0.114037  0.0  0.000000   \n",
      "2       0.000000  0.0   0.0  0.000000  0.000000  0.0  0.000000  0.0  0.000000   \n",
      "3       0.000000  0.0   0.0  0.000000  0.000000  0.0  0.000000  0.0  0.000000   \n",
      "4       0.000000  0.0   0.0  0.000000  0.000000  0.0  0.171079  0.0  0.000000   \n",
      "...          ...  ...   ...       ...       ...  ...       ...  ...       ...   \n",
      "212693  0.000000  0.0   0.0  0.000000  0.000000  0.0  0.000000  0.0  0.106295   \n",
      "212694  0.000000  0.0   0.0  0.000000  0.000000  0.0  0.000000  0.0  0.000000   \n",
      "212695  0.000000  0.0   0.0  0.000000  0.136148  0.0  0.000000  0.0  0.000000   \n",
      "212696  0.000000  0.0   0.0  0.000000  0.000000  0.0  0.000000  0.0  0.000000   \n",
      "212697  0.084093  0.0   0.0  0.000000  0.000000  0.0  0.000000  0.0  0.000000   \n",
      "\n",
      "         20  ...       yet       you  you are   you can  you have      your  \\\n",
      "0       0.0  ...  0.000000  0.000000      0.0  0.000000       0.0  0.000000   \n",
      "1       0.0  ...  0.000000  0.000000      0.0  0.000000       0.0  0.000000   \n",
      "2       0.0  ...  0.000000  0.000000      0.0  0.000000       0.0  0.000000   \n",
      "3       0.0  ...  0.223047  0.065756      0.0  0.117891       0.0  0.000000   \n",
      "4       0.0  ...  0.000000  0.000000      0.0  0.000000       0.0  0.000000   \n",
      "...     ...  ...       ...       ...      ...       ...       ...       ...   \n",
      "212693  0.0  ...  0.000000  0.000000      0.0  0.000000       0.0  0.000000   \n",
      "212694  0.0  ...  0.000000  0.000000      0.0  0.000000       0.0  0.000000   \n",
      "212695  0.0  ...  0.000000  0.000000      0.0  0.000000       0.0  0.000000   \n",
      "212696  0.0  ...  0.000000  0.069049      0.0  0.000000       0.0  0.000000   \n",
      "212697  0.0  ...  0.000000  0.069451      0.0  0.000000       0.0  0.091727   \n",
      "\n",
      "        yrs  zoloft  sentiment_score  condition  \n",
      "0       0.0     0.0          -0.4596        193  \n",
      "1       0.0     0.0           0.0736        173  \n",
      "2       0.0     0.0           0.0000        767  \n",
      "3       0.0     0.0           0.4013        789  \n",
      "4       0.0     0.0           0.9559         95  \n",
      "...     ...     ...              ...        ...  \n",
      "212693  0.0     0.0           0.9561         20  \n",
      "212694  0.0     0.0          -0.4767        472  \n",
      "212695  0.0     0.0          -0.7430        646  \n",
      "212696  0.0     0.0           0.8084        761  \n",
      "212697  0.0     0.0           0.6124        163  \n",
      "\n",
      "[212698 rows x 1002 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = tfidf_df.drop([ 'rating_scaled_usefulCount', 'scaled_usefulCount','rating'], axis=1)  # Features\n",
    "y = tfidf_df['rating_scaled_usefulCount']\n",
    "print(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_df['id'] = df['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.01704105]\n",
      " [0.12252252]\n",
      " [0.00661765]\n",
      " ...\n",
      " [0.02651515]\n",
      " [0.24159021]\n",
      " [0.71020408]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "y = y.values.reshape(-1, 1) if len(y.shape) == 1 else y\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Fit and transform the data\n",
    "y_scaled = scaler.fit_transform(y)\n",
    "\n",
    "print(y_scaled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0]\n",
      " [0]\n",
      " [0]\n",
      " ...\n",
      " [0]\n",
      " [0]\n",
      " [1]]\n"
     ]
    }
   ],
   "source": [
    "yy = (y_scaled > 0.5).astype(int)\n",
    "print(yy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of 0s: 206775\n",
      "Number of 1s: 5923\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "counts = np.bincount(yy.flatten())\n",
    "\n",
    "# Print the counts\n",
    "print(\"Number of 0s:\", counts[0])\n",
    "print(\"Number of 1s:\", counts[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_df['rating_scaled_usefulCount'] = yy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              10  100  10mg        11        12   14        15   16        18  \\\n",
      "0       0.000000  0.0   0.0  0.000000  0.000000  0.0  0.000000  0.0  0.000000   \n",
      "1       0.000000  0.0   0.0  0.139285  0.000000  0.0  0.114037  0.0  0.000000   \n",
      "2       0.000000  0.0   0.0  0.000000  0.000000  0.0  0.000000  0.0  0.000000   \n",
      "3       0.000000  0.0   0.0  0.000000  0.000000  0.0  0.000000  0.0  0.000000   \n",
      "4       0.000000  0.0   0.0  0.000000  0.000000  0.0  0.171079  0.0  0.000000   \n",
      "...          ...  ...   ...       ...       ...  ...       ...  ...       ...   \n",
      "212693  0.000000  0.0   0.0  0.000000  0.000000  0.0  0.000000  0.0  0.106295   \n",
      "212694  0.000000  0.0   0.0  0.000000  0.000000  0.0  0.000000  0.0  0.000000   \n",
      "212695  0.000000  0.0   0.0  0.000000  0.136148  0.0  0.000000  0.0  0.000000   \n",
      "212696  0.000000  0.0   0.0  0.000000  0.000000  0.0  0.000000  0.0  0.000000   \n",
      "212697  0.084093  0.0   0.0  0.000000  0.000000  0.0  0.000000  0.0  0.000000   \n",
      "\n",
      "         20  ...       yet       you  you are   you can  you have      your  \\\n",
      "0       0.0  ...  0.000000  0.000000      0.0  0.000000       0.0  0.000000   \n",
      "1       0.0  ...  0.000000  0.000000      0.0  0.000000       0.0  0.000000   \n",
      "2       0.0  ...  0.000000  0.000000      0.0  0.000000       0.0  0.000000   \n",
      "3       0.0  ...  0.223047  0.065756      0.0  0.117891       0.0  0.000000   \n",
      "4       0.0  ...  0.000000  0.000000      0.0  0.000000       0.0  0.000000   \n",
      "...     ...  ...       ...       ...      ...       ...       ...       ...   \n",
      "212693  0.0  ...  0.000000  0.000000      0.0  0.000000       0.0  0.000000   \n",
      "212694  0.0  ...  0.000000  0.000000      0.0  0.000000       0.0  0.000000   \n",
      "212695  0.0  ...  0.000000  0.000000      0.0  0.000000       0.0  0.000000   \n",
      "212696  0.0  ...  0.000000  0.069049      0.0  0.000000       0.0  0.000000   \n",
      "212697  0.0  ...  0.000000  0.069451      0.0  0.000000       0.0  0.091727   \n",
      "\n",
      "        yrs  zoloft  sentiment_score  condition  \n",
      "0       0.0     0.0          -0.4596        193  \n",
      "1       0.0     0.0           0.0736        173  \n",
      "2       0.0     0.0           0.0000        767  \n",
      "3       0.0     0.0           0.4013        789  \n",
      "4       0.0     0.0           0.9559         95  \n",
      "...     ...     ...              ...        ...  \n",
      "212693  0.0     0.0           0.9561         20  \n",
      "212694  0.0     0.0          -0.4767        472  \n",
      "212695  0.0     0.0          -0.7430        646  \n",
      "212696  0.0     0.0           0.8084        761  \n",
      "212697  0.0     0.0           0.6124        163  \n",
      "\n",
      "[212698 rows x 1002 columns]\n",
      "0         0\n",
      "1         0\n",
      "2         0\n",
      "3         0\n",
      "4         0\n",
      "         ..\n",
      "212693    1\n",
      "212694    0\n",
      "212695    0\n",
      "212696    0\n",
      "212697    1\n",
      "Name: rating_scaled_usefulCount, Length: 212698, dtype: int32\n",
      "Class distribution in 'rating_scaled_usefulCount':\n",
      "rating_scaled_usefulCount\n",
      "0    206775\n",
      "1      5923\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(X)\n",
    "print(tfidf_df['rating_scaled_usefulCount'])\n",
    "# Assuming 'rating_scaled_usefulCount' is your target variable\n",
    "y = tfidf_df['rating_scaled_usefulCount']\n",
    "\n",
    "# Count the occurrences of each value\n",
    "class_distribution = y.value_counts()\n",
    "\n",
    "# Display the class distribution\n",
    "print(\"Class distribution in 'rating_scaled_usefulCount':\")\n",
    "print(class_distribution)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Chief Engineer (C)\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:785: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "X = tfidf_df.drop(['rating_scaled_usefulCount', 'scaled_usefulCount', 'rating'], axis=1)\n",
    "y = tfidf_df['rating_scaled_usefulCount']\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X, y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0         0\n",
      "1         0\n",
      "2         0\n",
      "3         0\n",
      "4         0\n",
      "         ..\n",
      "413545    1\n",
      "413546    1\n",
      "413547    1\n",
      "413548    1\n",
      "413549    1\n",
      "Name: rating_scaled_usefulCount, Length: 413550, dtype: int32\n"
     ]
    }
   ],
   "source": [
    "print(y_train_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rating_scaled_usefulCount\n",
      "0    206775\n",
      "1    206775\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(y_train_resampled.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_train_resampled, y_train_resampled, test_size=0.3, random_state=42, stratify=y_train_resampled\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_no_id = X_train.drop(['id'], axis=1)\n",
    "X_test_no_id = X_test.drop(['id'], axis = 1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              10  100  10mg        11   12   14   15        16   18   20  ...  \\\n",
      "69191   0.069345  0.0   0.0  0.000000  0.0  0.0  0.0  0.000000  0.0  0.0  ...   \n",
      "198219  0.000000  0.0   0.0  0.000000  0.0  0.0  0.0  0.000000  0.0  0.0  ...   \n",
      "56512   0.000000  0.0   0.0  0.000000  0.0  0.0  0.0  0.000000  0.0  0.0  ...   \n",
      "407528  0.000000  0.0   0.0  0.000000  0.0  0.0  0.0  0.000000  0.0  0.0  ...   \n",
      "304921  0.000000  0.0   0.0  0.000000  0.0  0.0  0.0  0.000000  0.0  0.0  ...   \n",
      "...          ...  ...   ...       ...  ...  ...  ...       ...  ...  ...  ...   \n",
      "121232  0.000000  0.0   0.0  0.000000  0.0  0.0  0.0  0.000000  0.0  0.0  ...   \n",
      "223988  0.108511  0.0   0.0  0.000000  0.0  0.0  0.0  0.000000  0.0  0.0  ...   \n",
      "392839  0.021815  0.0   0.0  0.000000  0.0  0.0  0.0  0.194667  0.0  0.0  ...   \n",
      "162831  0.000000  0.0   0.0  0.000000  0.0  0.0  0.0  0.000000  0.0  0.0  ...   \n",
      "289006  0.076248  0.0   0.0  0.117514  0.0  0.0  0.0  0.000000  0.0  0.0  ...   \n",
      "\n",
      "        yet       you  you are  you can  you have      your  yrs  zoloft  \\\n",
      "69191   0.0  0.171813      0.0      0.0       0.0  0.000000  0.0     0.0   \n",
      "198219  0.0  0.000000      0.0      0.0       0.0  0.000000  0.0     0.0   \n",
      "56512   0.0  0.000000      0.0      0.0       0.0  0.000000  0.0     0.0   \n",
      "407528  0.0  0.000000      0.0      0.0       0.0  0.133231  0.0     0.0   \n",
      "304921  0.0  0.000000      0.0      0.0       0.0  0.000000  0.0     0.0   \n",
      "...     ...       ...      ...      ...       ...       ...  ...     ...   \n",
      "121232  0.0  0.000000      0.0      0.0       0.0  0.000000  0.0     0.0   \n",
      "223988  0.0  0.089618      0.0      0.0       0.0  0.000000  0.0     0.0   \n",
      "392839  0.0  0.000000      0.0      0.0       0.0  0.000000  0.0     0.0   \n",
      "162831  0.0  0.235215      0.0      0.0       0.0  0.207107  0.0     0.0   \n",
      "289006  0.0  0.000000      0.0      0.0       0.0  0.000000  0.0     0.0   \n",
      "\n",
      "        sentiment_score  condition  \n",
      "69191         -0.392300        658  \n",
      "198219         0.359700        533  \n",
      "56512          0.515500         95  \n",
      "407528         0.385584        221  \n",
      "304921         0.497483        207  \n",
      "...                 ...        ...  \n",
      "121232        -0.624500         94  \n",
      "223988         0.355300         68  \n",
      "392839        -0.393765        825  \n",
      "162831        -0.830200         95  \n",
      "289006        -0.937944        580  \n",
      "\n",
      "[289485 rows x 1002 columns]\n",
      "(289485,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_no_id)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Chief Engineer (C)\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:785: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Chief Engineer (C)\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:785: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.61      0.62     62033\n",
      "           1       0.62      0.62      0.62     62032\n",
      "\n",
      "    accuracy                           0.62    124065\n",
      "   macro avg       0.62      0.62      0.62    124065\n",
      "weighted avg       0.62      0.62      0.62    124065\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Chief Engineer (C)\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:785: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Chief Engineer (C)\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:785: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perceptron:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      1.00      0.67     62033\n",
      "           1       0.30      0.00      0.00     62032\n",
      "\n",
      "    accuracy                           0.50    124065\n",
      "   macro avg       0.40      0.50      0.33    124065\n",
      "weighted avg       0.40      0.50      0.33    124065\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Chief Engineer (C)\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:785: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Chief Engineer (C)\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:785: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge Classifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.62      0.62     62033\n",
      "           1       0.62      0.63      0.63     62032\n",
      "\n",
      "    accuracy                           0.63    124065\n",
      "   macro avg       0.63      0.63      0.63    124065\n",
      "weighted avg       0.63      0.63      0.63    124065\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Chief Engineer (C)\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:785: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Negative values in data passed to MultinomialNB (input X)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Chief Engineer (C)\\Documents\\GitHub\\data-science-project\\Bhavya_Reccomender_tldf.ipynb Cell 20\u001b[0m line \u001b[0;36m3\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Chief%20Engineer%20%28C%29/Documents/GitHub/data-science-project/Bhavya_Reccomender_tldf.ipynb#Y124sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m \u001b[39m# Multinomial Naive Bayes\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Chief%20Engineer%20%28C%29/Documents/GitHub/data-science-project/Bhavya_Reccomender_tldf.ipynb#Y124sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m nb \u001b[39m=\u001b[39m MultinomialNB()\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Chief%20Engineer%20%28C%29/Documents/GitHub/data-science-project/Bhavya_Reccomender_tldf.ipynb#Y124sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m nb\u001b[39m.\u001b[39;49mfit(X_train_no_id, y_train)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Chief%20Engineer%20%28C%29/Documents/GitHub/data-science-project/Bhavya_Reccomender_tldf.ipynb#Y124sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m y_pred_nb \u001b[39m=\u001b[39m nb\u001b[39m.\u001b[39mpredict(X_test_no_id)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Chief%20Engineer%20%28C%29/Documents/GitHub/data-science-project/Bhavya_Reccomender_tldf.ipynb#Y124sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mMultinomial Naive Bayes:\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Chief Engineer (C)\\anaconda3\\lib\\site-packages\\sklearn\\base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[0;32m   1147\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[0;32m   1148\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[0;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1150\u001b[0m     )\n\u001b[0;32m   1151\u001b[0m ):\n\u001b[1;32m-> 1152\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Chief Engineer (C)\\anaconda3\\lib\\site-packages\\sklearn\\naive_bayes.py:772\u001b[0m, in \u001b[0;36m_BaseDiscreteNB.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    770\u001b[0m n_classes \u001b[39m=\u001b[39m Y\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]\n\u001b[0;32m    771\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_init_counters(n_classes, n_features)\n\u001b[1;32m--> 772\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_count(X, Y)\n\u001b[0;32m    773\u001b[0m alpha \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_alpha()\n\u001b[0;32m    774\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_update_feature_log_prob(alpha)\n",
      "File \u001b[1;32mc:\\Users\\Chief Engineer (C)\\anaconda3\\lib\\site-packages\\sklearn\\naive_bayes.py:894\u001b[0m, in \u001b[0;36mMultinomialNB._count\u001b[1;34m(self, X, Y)\u001b[0m\n\u001b[0;32m    892\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_count\u001b[39m(\u001b[39mself\u001b[39m, X, Y):\n\u001b[0;32m    893\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Count and smooth feature occurrences.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 894\u001b[0m     check_non_negative(X, \u001b[39m\"\u001b[39;49m\u001b[39mMultinomialNB (input X)\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m    895\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfeature_count_ \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m safe_sparse_dot(Y\u001b[39m.\u001b[39mT, X)\n\u001b[0;32m    896\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclass_count_ \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m Y\u001b[39m.\u001b[39msum(axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Chief Engineer (C)\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1489\u001b[0m, in \u001b[0;36mcheck_non_negative\u001b[1;34m(X, whom)\u001b[0m\n\u001b[0;32m   1486\u001b[0m     X_min \u001b[39m=\u001b[39m xp\u001b[39m.\u001b[39mmin(X)\n\u001b[0;32m   1488\u001b[0m \u001b[39mif\u001b[39;00m X_min \u001b[39m<\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m-> 1489\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mNegative values in data passed to \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m whom)\n",
      "\u001b[1;31mValueError\u001b[0m: Negative values in data passed to MultinomialNB (input X)"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression, Perceptron, RidgeClassifier, SGDClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Assuming you already have X_train_no_id and y_train\n",
    "\n",
    "# Logistic Regression\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train_no_id, y_train)\n",
    "y_pred_logreg = logreg.predict(X_test_no_id)\n",
    "print(\"Logistic Regression:\")\n",
    "print(classification_report(y_test, y_pred_logreg))\n",
    "\n",
    "# Perceptron\n",
    "perceptron = Perceptron()\n",
    "perceptron.fit(X_train_no_id, y_train)\n",
    "y_pred_perceptron = perceptron.predict(X_test_no_id)\n",
    "print(\"Perceptron:\")\n",
    "print(classification_report(y_test, y_pred_perceptron))\n",
    "\n",
    "# Ridge Classifier\n",
    "ridge_classifier = RidgeClassifier()\n",
    "ridge_classifier.fit(X_train_no_id, y_train)\n",
    "y_pred_ridge = ridge_classifier.predict(X_test_no_id)\n",
    "print(\"Ridge Classifier:\")\n",
    "print(classification_report(y_test, y_pred_ridge))\n",
    "\n",
    "# Multinomial Naive Bayes\n",
    "nb = MultinomialNB()\n",
    "nb.fit(X_train_no_id, y_train)\n",
    "y_pred_nb = nb.predict(X_test_no_id)\n",
    "print(\"Multinomial Naive Bayes:\")\n",
    "print(classification_report(y_test, y_pred_nb))\n",
    "\n",
    "# SGD Classifier\n",
    "sgd_classifier = SGDClassifier()\n",
    "sgd_classifier.fit(X_train_no_id, y_train)\n",
    "y_pred_sgd = sgd_classifier.predict(X_test_no_id)\n",
    "print(\"SGD Classifier:\")\n",
    "print(classification_report(y_test, y_pred_sgd))\n",
    "\n",
    "# Linear SVC\n",
    "linear_svc = LinearSVC()\n",
    "linear_svc.fit(X_train_no_id, y_train)\n",
    "y_pred_svc = linear_svc.predict(X_test_no_id)\n",
    "print(\"Linear SVC:\")\n",
    "print(classification_report(y_test, y_pred_svc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Chief Engineer (C)\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:785: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Chief Engineer (C)\\Documents\\GitHub\\data-science-project\\Bhavya_Reccomender_tldf.ipynb Cell 19\u001b[0m line \u001b[0;36m9\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Chief%20Engineer%20%28C%29/Documents/GitHub/data-science-project/Bhavya_Reccomender_tldf.ipynb#Y120sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m tsne \u001b[39m=\u001b[39m TSNE(random_state\u001b[39m=\u001b[39m\u001b[39m42\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Chief%20Engineer%20%28C%29/Documents/GitHub/data-science-project/Bhavya_Reccomender_tldf.ipynb#Y120sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39m# Fit and transform t-SNE on the training data\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Chief%20Engineer%20%28C%29/Documents/GitHub/data-science-project/Bhavya_Reccomender_tldf.ipynb#Y120sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m X_train_tsne \u001b[39m=\u001b[39m tsne\u001b[39m.\u001b[39;49mfit_transform(X_train_no_id)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Chief%20Engineer%20%28C%29/Documents/GitHub/data-science-project/Bhavya_Reccomender_tldf.ipynb#Y120sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39m# Fit and transform t-SNE on the test data\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Chief%20Engineer%20%28C%29/Documents/GitHub/data-science-project/Bhavya_Reccomender_tldf.ipynb#Y120sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m X_test_tsne \u001b[39m=\u001b[39m tsne\u001b[39m.\u001b[39mfit_transform(X_test_no_id)\n",
      "File \u001b[1;32mc:\\Users\\Chief Engineer (C)\\anaconda3\\lib\\site-packages\\sklearn\\utils\\_set_output.py:157\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    155\u001b[0m \u001b[39m@wraps\u001b[39m(f)\n\u001b[0;32m    156\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped\u001b[39m(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m--> 157\u001b[0m     data_to_wrap \u001b[39m=\u001b[39m f(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    158\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data_to_wrap, \u001b[39mtuple\u001b[39m):\n\u001b[0;32m    159\u001b[0m         \u001b[39m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    160\u001b[0m         return_tuple \u001b[39m=\u001b[39m (\n\u001b[0;32m    161\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[39m0\u001b[39m], X, \u001b[39mself\u001b[39m),\n\u001b[0;32m    162\u001b[0m             \u001b[39m*\u001b[39mdata_to_wrap[\u001b[39m1\u001b[39m:],\n\u001b[0;32m    163\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\Chief Engineer (C)\\anaconda3\\lib\\site-packages\\sklearn\\base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[0;32m   1147\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[0;32m   1148\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[0;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1150\u001b[0m     )\n\u001b[0;32m   1151\u001b[0m ):\n\u001b[1;32m-> 1152\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Chief Engineer (C)\\anaconda3\\lib\\site-packages\\sklearn\\manifold\\_t_sne.py:1111\u001b[0m, in \u001b[0;36mTSNE.fit_transform\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m   1090\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Fit X into an embedded space and return that transformed output.\u001b[39;00m\n\u001b[0;32m   1091\u001b[0m \n\u001b[0;32m   1092\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1108\u001b[0m \u001b[39m    Embedding of the training data in low-dimensional space.\u001b[39;00m\n\u001b[0;32m   1109\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1110\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_params_vs_input(X)\n\u001b[1;32m-> 1111\u001b[0m embedding \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit(X)\n\u001b[0;32m   1112\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membedding_ \u001b[39m=\u001b[39m embedding\n\u001b[0;32m   1113\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membedding_\n",
      "File \u001b[1;32mc:\\Users\\Chief Engineer (C)\\anaconda3\\lib\\site-packages\\sklearn\\manifold\\_t_sne.py:1001\u001b[0m, in \u001b[0;36mTSNE._fit\u001b[1;34m(self, X, skip_num_points)\u001b[0m\n\u001b[0;32m    995\u001b[0m \u001b[39m# Degrees of freedom of the Student's t-distribution. The suggestion\u001b[39;00m\n\u001b[0;32m    996\u001b[0m \u001b[39m# degrees_of_freedom = n_components - 1 comes from\u001b[39;00m\n\u001b[0;32m    997\u001b[0m \u001b[39m# \"Learning a Parametric Embedding by Preserving Local Structure\"\u001b[39;00m\n\u001b[0;32m    998\u001b[0m \u001b[39m# Laurens van der Maaten, 2009.\u001b[39;00m\n\u001b[0;32m    999\u001b[0m degrees_of_freedom \u001b[39m=\u001b[39m \u001b[39mmax\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_components \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m)\n\u001b[1;32m-> 1001\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_tsne(\n\u001b[0;32m   1002\u001b[0m     P,\n\u001b[0;32m   1003\u001b[0m     degrees_of_freedom,\n\u001b[0;32m   1004\u001b[0m     n_samples,\n\u001b[0;32m   1005\u001b[0m     X_embedded\u001b[39m=\u001b[39;49mX_embedded,\n\u001b[0;32m   1006\u001b[0m     neighbors\u001b[39m=\u001b[39;49mneighbors_nn,\n\u001b[0;32m   1007\u001b[0m     skip_num_points\u001b[39m=\u001b[39;49mskip_num_points,\n\u001b[0;32m   1008\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Chief Engineer (C)\\anaconda3\\lib\\site-packages\\sklearn\\manifold\\_t_sne.py:1069\u001b[0m, in \u001b[0;36mTSNE._tsne\u001b[1;34m(self, P, degrees_of_freedom, n_samples, X_embedded, neighbors, skip_num_points)\u001b[0m\n\u001b[0;32m   1067\u001b[0m     opt_args[\u001b[39m\"\u001b[39m\u001b[39mmomentum\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m0.8\u001b[39m\n\u001b[0;32m   1068\u001b[0m     opt_args[\u001b[39m\"\u001b[39m\u001b[39mn_iter_without_progress\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_iter_without_progress\n\u001b[1;32m-> 1069\u001b[0m     params, kl_divergence, it \u001b[39m=\u001b[39m _gradient_descent(obj_func, params, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mopt_args)\n\u001b[0;32m   1071\u001b[0m \u001b[39m# Save the final number of iterations\u001b[39;00m\n\u001b[0;32m   1072\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_iter_ \u001b[39m=\u001b[39m it\n",
      "File \u001b[1;32mc:\\Users\\Chief Engineer (C)\\anaconda3\\lib\\site-packages\\sklearn\\manifold\\_t_sne.py:402\u001b[0m, in \u001b[0;36m_gradient_descent\u001b[1;34m(objective, p0, it, n_iter, n_iter_check, n_iter_without_progress, momentum, learning_rate, min_gain, min_grad_norm, verbose, args, kwargs)\u001b[0m\n\u001b[0;32m    399\u001b[0m \u001b[39m# only compute the error when needed\u001b[39;00m\n\u001b[0;32m    400\u001b[0m kwargs[\u001b[39m\"\u001b[39m\u001b[39mcompute_error\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m check_convergence \u001b[39mor\u001b[39;00m i \u001b[39m==\u001b[39m n_iter \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m--> 402\u001b[0m error, grad \u001b[39m=\u001b[39m objective(p, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    404\u001b[0m inc \u001b[39m=\u001b[39m update \u001b[39m*\u001b[39m grad \u001b[39m<\u001b[39m \u001b[39m0.0\u001b[39m\n\u001b[0;32m    405\u001b[0m dec \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39minvert(inc)\n",
      "File \u001b[1;32mc:\\Users\\Chief Engineer (C)\\anaconda3\\lib\\site-packages\\sklearn\\manifold\\_t_sne.py:283\u001b[0m, in \u001b[0;36m_kl_divergence_bh\u001b[1;34m(params, P, degrees_of_freedom, n_samples, n_components, angle, skip_num_points, verbose, compute_error, num_threads)\u001b[0m\n\u001b[0;32m    280\u001b[0m indptr \u001b[39m=\u001b[39m P\u001b[39m.\u001b[39mindptr\u001b[39m.\u001b[39mastype(np\u001b[39m.\u001b[39mint64, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m    282\u001b[0m grad \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mzeros(X_embedded\u001b[39m.\u001b[39mshape, dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mfloat32)\n\u001b[1;32m--> 283\u001b[0m error \u001b[39m=\u001b[39m _barnes_hut_tsne\u001b[39m.\u001b[39;49mgradient(\n\u001b[0;32m    284\u001b[0m     val_P,\n\u001b[0;32m    285\u001b[0m     X_embedded,\n\u001b[0;32m    286\u001b[0m     neighbors,\n\u001b[0;32m    287\u001b[0m     indptr,\n\u001b[0;32m    288\u001b[0m     grad,\n\u001b[0;32m    289\u001b[0m     angle,\n\u001b[0;32m    290\u001b[0m     n_components,\n\u001b[0;32m    291\u001b[0m     verbose,\n\u001b[0;32m    292\u001b[0m     dof\u001b[39m=\u001b[39;49mdegrees_of_freedom,\n\u001b[0;32m    293\u001b[0m     compute_error\u001b[39m=\u001b[39;49mcompute_error,\n\u001b[0;32m    294\u001b[0m     num_threads\u001b[39m=\u001b[39;49mnum_threads,\n\u001b[0;32m    295\u001b[0m )\n\u001b[0;32m    296\u001b[0m c \u001b[39m=\u001b[39m \u001b[39m2.0\u001b[39m \u001b[39m*\u001b[39m (degrees_of_freedom \u001b[39m+\u001b[39m \u001b[39m1.0\u001b[39m) \u001b[39m/\u001b[39m degrees_of_freedom\n\u001b[0;32m    297\u001b[0m grad \u001b[39m=\u001b[39m grad\u001b[39m.\u001b[39mravel()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# from sklearn.manifold import TSNE\n",
    "# import pandas as pd\n",
    "\n",
    "# tsne = TSNE(random_state=42)\n",
    "\n",
    "# X_train_tsne = tsne.fit_transform(X_train_no_id)\n",
    "# X_test_tsne = tsne.fit_transform(X_test_no_id)\n",
    "\n",
    "# train_tsne_df = pd.DataFrame(X_train_tsne, columns=['tsne1', 'tsne2'])\n",
    "# train_tsne_df['Class'] = y_train.values\n",
    "\n",
    "# test_tsne_df = pd.DataFrame(X_test_tsne, columns=['tsne1', 'tsne2'])\n",
    "# test_tsne_df['Class'] = y_test.values\n",
    "\n",
    "# plt.figure(figsize=(12, 6))\n",
    "# sns.scatterplot(x='tsne1', y='tsne2', hue='Class', data=train_tsne_df, palette='viridis')\n",
    "# plt.title('t-SNE Visualization of Training Data')\n",
    "# plt.show()\n",
    "\n",
    "# plt.figure(figsize=(12, 6))\n",
    "# sns.scatterplot(x='tsne1', y='tsne2', hue='Class', data=test_tsne_df, palette='viridis')\n",
    "# plt.title('t-SNE Visualization of Test Data')\n",
    "# plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
